# =============================================================================
# Manga-Translator Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# =============================================================================
# Gemini API (Required for translation)
# =============================================================================
# Get your API key from: https://aistudio.google.com/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# API URL (default is Google's API, change if using proxy)
GEMINI_API_URL=https://generativelanguage.googleapis.com/v1beta/openai

# Model to use for translation
# Options: gemini-2.0-flash (fast), gemini-1.5-pro (better quality)
GEMINI_MODEL=gemini-2.0-flash

# =============================================================================
# Server Configuration
# =============================================================================
HOST=0.0.0.0
PORT=5000
DEBUG=false
SECRET_KEY=your-secret-key-change-in-production

# =============================================================================
# Performance Settings
# =============================================================================
# Number of parallel OCR workers (adjust based on CPU cores)
OCR_WORKERS=4

# Thread settings for OpenVINO/NumPy
OMP_NUM_THREADS=4
MKL_NUM_THREADS=4
OPENBLAS_NUM_THREADS=4

# =============================================================================
# Processing Mode (optional, can be set per-request)
# =============================================================================
# Default mode: realtime, quality, premium
DEFAULT_MODE=realtime

# Default inpainting method: auto, canvas, opencv, flux
DEFAULT_INPAINT=auto

# =============================================================================
# Optional: HuggingFace Token (for downloading gated models)
# =============================================================================
# HF_TOKEN=your_huggingface_token_here
